{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Experiment on Kumar's EEG Imagined speech dataset\n",
    "\n",
    "Run this experiment to obtain a similar result as the one publisher in the paper\n",
    "\n",
    "```latex\n",
    "@article{gallo2024eeg,\n",
    "  title={Thinking is Like a Sequence of Words},\n",
    "  author={Gallo, Ignzio and Coarsh, Silvia},\n",
    "  journal={IJCNN},\n",
    "  volume={??},\n",
    "  pages={??--??},\n",
    "  year={2024},\n",
    "  publisher={IEEE}\n",
    "}\n",
    "```\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import yaml\n",
    "import mne\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_save_dir(args):\n",
    "    if \"subject_num\" in args:\n",
    "        if type(args['subject_num']) is not list:\n",
    "            args['subject_num'] = [args['subject_num']]\n",
    "\n",
    "        subjs_str = ','.join(str(x) for x in args['subject_num'])\n",
    "        args['save_dir'] = os.path.join(args['save_dir'], subjs_str, datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "    else:\n",
    "        args['save_dir'] = os.path.join(args['save_dir'], datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "    if not os.path.isdir(args['save_dir']):\n",
    "        os.makedirs(args['save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, column_names):\n",
    "        column_names.insert(0, \"time_stamp\")\n",
    "        self.df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    def add_row(self, row_list):\n",
    "        row_list.insert(0, str(dt.datetime.now()))\n",
    "        # print(row_list)\n",
    "        self.df.loc[len(self.df)] = row_list\n",
    "\n",
    "    def save_to_csv(self, filepath):\n",
    "        self.df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class2index(args):\n",
    "    basename = os.path.basename(os.path.normpath(args['data_dir']))\n",
    "    if basename ==  'Digit':\n",
    "        cls_names = ['0','1','2','3','4','5','6','7','8','9']\n",
    "    elif basename == 'Char':\n",
    "        cls_names = ['a','c','f','h','j','m','p','s','t','y']\n",
    "    elif basename == 'Image':\n",
    "        cls_names = ['apple','car','dog','gold','mobile','rose','scooter','tiger','wallet','watch']\n",
    "    else:\n",
    "        raise Exception(\"Sorry, unrecognized dir name:\" + basename) \n",
    "    class_to_index_dic = dict(zip(cls_names, range(len(cls_names))))\n",
    "    print(class_to_index_dic)\n",
    "    return class_to_index_dic\n",
    "\n",
    "def file_name_to_cls_index(file_name, class_to_index_dic):\n",
    "    name, _ = file_name.split('.')\n",
    "    _,cls = name.split('_')\n",
    "    return class_to_index_dic[cls.lower()]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_kumar_raw(args, unsupervised=False):\n",
    "    print(\"Dataset dir:\", args['data_dir'])\n",
    "    files = os.listdir(args['data_dir'])\n",
    "    num_raw_files=len(files)\n",
    "\n",
    "    # mapping class name to indices\n",
    "    charcls2index = class2index(args)\n",
    "\n",
    "    # some statistics on all the raw files\n",
    "    ts_len = []\n",
    "    ts_max = []\n",
    "    for fi in files:\n",
    "        data = mne.io.read_raw_edf(os.path.join(args['data_dir'],fi), verbose='CRITICAL')\n",
    "        # read channels 'AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4', 'RAW_CQ'\n",
    "        raw_data = data[2:16][0]\n",
    "        n_channels, len_time_series = raw_data.shape\n",
    "        ts_len.append(len_time_series)\n",
    "        ts_max.append(np.max(raw_data))\n",
    "    print(f\"Lenght Time series: MIN={np.min(ts_len)}, MAX={np.max(ts_len)}\")\n",
    "    print(f\"Max value in Time series: {np.max(ts_max)}\")\n",
    "    print(f\"Num raw files: {num_raw_files}\")\n",
    "    print(f\"Num channels: {n_channels}\")\n",
    "\n",
    "    # Read data and scale them\n",
    "    MAX_LEN_TS = 1280\n",
    "    SCALE = 1000\n",
    "    assert MAX_LEN_TS <= np.min(ts_len), f\"{MAX_LEN_TS} is not <= {np.min(ts_len)}\"\n",
    "\n",
    "    X = np.zeros((num_raw_files,n_channels,MAX_LEN_TS))\n",
    "    Y = np.zeros((num_raw_files,))\n",
    "    for idx, fi in enumerate(files):\n",
    "        data = mne.io.read_raw_edf(os.path.join(args['data_dir'], fi), verbose='CRITICAL')\n",
    "        raw_data_scaled = data[2:16][0]*SCALE\n",
    "        X[idx,:,:] = raw_data_scaled[:,0:MAX_LEN_TS]\n",
    "        Y[idx] = file_name_to_cls_index(fi, charcls2index)\n",
    "\n",
    "    # sliding window on the source timeseries\n",
    "    npt = args['vocab_size']\n",
    "    X_new = np.zeros((36110, npt, n_channels))\n",
    "    Y_new = np.zeros((36110,))\n",
    "\n",
    "    stride = 8\n",
    "    ctr = 0\n",
    "    for i in range(0,num_raw_files):\n",
    "        y = Y[i]\n",
    "        a= X[i,:,:]\n",
    "        a = a.transpose()\n",
    "        val = 0\n",
    "        while val<=(len(a)-npt):\n",
    "            x = a[val:val+npt,:]\n",
    "            X_new[ctr,:,:] = x\n",
    "            Y_new[ctr] = y\n",
    "            val = val+stride\n",
    "            ctr = ctr+1          \n",
    "\n",
    "    mean, std = X_new.mean(), X_new.std()\n",
    "    print(\"Input data: mean =\", mean, \", std =\", std) # used for input data Normalization\n",
    "    print(\"Kumar Dataset shape:\", X_new.shape, \", min:\", np.min(X_new), \", max:\", np.max(X_new))\n",
    "\n",
    "    # Random split. It is better to split the 230 files before the sliding window...\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(np.float32(X_new), Y_new.astype(int), test_size=0.2, random_state=1)   \n",
    "\n",
    "    # Convert NumPy arrays to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    Y_test = torch.tensor(Y_test, dtype=torch.long)\n",
    "    print(\"Training shape:\", X_train.shape)\n",
    "    print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "    # Convert data to DataLoader\n",
    "    train_dataset = TensorDataset(X_train, Y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True)\n",
    "    test_dataset = TensorDataset(X_test, Y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "Deep neural network based on a basic Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetTraST(nn.Module):\n",
    "    def __init__(self, args): \n",
    "        super(NetTraST, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(args['vocab_size'])\n",
    "        p = args['kernel_size'] // 2\n",
    "        self.conv1 = nn.Conv1d(in_channels=args['vocab_size'], out_channels=args['kernel_num'], kernel_size=args['kernel_size'], stride=1, padding=p)\n",
    "        \n",
    "        #self.conv2 = nn.Conv1d(in_channels=args['embed_dim'], out_channels=args['kernel_num'], kernel_size=args['kernel_size'], stride=1, padding=p)\n",
    "        self.upsamp = nn.Upsample((args['embed_dim']))\n",
    "        \n",
    "        self.rrelu = nn.RReLU(0.1, 0.3)\n",
    "        nl=3 \n",
    "        self.spatial_tra = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=args['embed_dim'],\n",
    "                nhead=args['nhead'],\n",
    "                dim_feedforward=args['dim_feedforward'],\n",
    "            ),\n",
    "            num_layers=nl,\n",
    "        )\n",
    "        #self.temporal_tra = nn.TransformerEncoder(\n",
    "        #    nn.TransformerEncoderLayer(\n",
    "        #        d_model=args['vocab_size'],\n",
    "        #        nhead=args['nhead'],\n",
    "        #        dim_feedforward=args['dim_feedforward'],\n",
    "        #    ),\n",
    "        #    num_layers=nl,\n",
    "        #)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=args['kernel_num'],\n",
    "                nhead=args['nhead'],\n",
    "                dim_feedforward=args['dim_feedforward'],\n",
    "            ),\n",
    "            num_layers=args['num_layers'],\n",
    "        )\n",
    "        self.batch_norm3 = nn.BatchNorm1d(args['kernel_num'])\n",
    "        self.fl = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(args['kernel_num']*args['embed_dim'], args['kernel_num'])\n",
    "        self.dropout = nn.Dropout(args['dropout'])\n",
    "        self.fc2 = nn.Linear(args['kernel_num'], args['class_num'])\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.batch_norm1(x)\n",
    "        \n",
    "        x1 = self.conv1(x) \n",
    "        x1 = self.spatial_tra(x1)\n",
    "        \n",
    "        #x2 = x.permute(0, 2, 1)\n",
    "        #x2 = self.conv2(x2) \n",
    "        #x2 = self.temporal_tra(x2)\n",
    "        #x2 = self.upsamp(x2)\n",
    "\n",
    "        x = x1 #x1+x2 \n",
    "        #x = torch.cat((x1, x2), 1)\n",
    "        \n",
    "        # Reshape the input for the Transformer layer\n",
    "        x = x.permute(2, 0, 1)  # Change the shape to (sequence_length, batch_size, input_size)\n",
    "        x = self.transformer(x)\n",
    "        # Reshape the output back to the original shape\n",
    "        x = x.permute(1, 2, 0)  # Change the shape to (batch_size, input_size, sequence_length)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.fl(x)\n",
    "        x = self.rrelu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_raw(args, model, test_loader, criterion):\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tot_loss = 0\n",
    "        test_corrects = torch.tensor(0, device=args['device'])\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(args['device'])\n",
    "            labels = labels.to(args['device'])\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            corrects = (torch.max(outputs, 1)[1].view(labels.size()).data == labels.data).sum()\n",
    "            test_corrects += corrects\n",
    "            tot_loss += loss\n",
    "\n",
    "        ts_acc = 100.0 * test_corrects/len(test_loader.dataset)\n",
    "        #print(f'Test Accuracy: {ts_acc:.4f}, Test loss: {tot_loss:.6f}')  \n",
    "    return ts_acc.cpu().item(), tot_loss\n",
    "\n",
    "\n",
    "def train_raw(args, model, train_loader, optimizer, criterion, test_loader, subj, scheduler=None): \n",
    "    metrics = Metrics([\"epoch\", \"lr\", \"train_loss\", \"train_acc\", \"test_loss\", \"test_acc\", \"best_test_acc\"])\n",
    "    # Training loop\n",
    "    best_acc = 0\n",
    "    patience_counter = 0\n",
    "    steps = 0\n",
    "    loop_obj = tqdm(range(args['epochs']))\n",
    "    loop_obj.set_postfix_str(f\"Best val. acc.: {best_acc:.4f}\")  # Adds text after progressbar\n",
    "    for epoch in loop_obj:\n",
    "        loop_obj.set_description(f\"Subj.: {subj}, Training epoch: {epoch+1}\")  # Adds text before progessbar\n",
    "        train_corrects = torch.tensor(0, device=args['device'])\n",
    "        tot_loss = 0\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(args['device'])\n",
    "\n",
    "            labels = labels.to(args['device'])\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            corrects = (torch.max(outputs, 1)[1].view(labels.size()).data == labels.data).sum()\n",
    "            train_corrects += corrects\n",
    "            tot_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if scheduler: scheduler.step()\n",
    "\n",
    "        tr_acc = 100.0 * train_corrects/len(train_loader.dataset)\n",
    "        # Validation\n",
    "        dev_acc, test_loss = evaluation_raw(args, model, test_loader, criterion)\n",
    "\n",
    "        if dev_acc > best_acc:\n",
    "            best_acc = dev_acc\n",
    "            patience_counter = 0\n",
    "            loop_obj.set_postfix_str(f\"Best val. acc.: {best_acc:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        EP=args['epochs']\n",
    "        #print(f'Epoch [{epoch+1}/{EP}] Tr. Loss: {tot_loss.item():.4f} Val. Accuracy: {dev_acc:.4f} Best Val. Accuracy: {best_acc:.4f}')\n",
    "        lr=optimizer.param_groups[0][\"lr\"]\n",
    "        metrics.add_row([epoch+1, lr, tot_loss.cpu().item(), tr_acc.cpu().item(), test_loss.cpu().item(), dev_acc, best_acc])\n",
    "        metrics.save_to_csv(os.path.join(args['save_dir'], \"metrics_classifciation.csv\"))\n",
    "\n",
    "        if patience_counter >= args['early_stopping_patience']:\n",
    "            print(\"Early stopping...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an experiment\n",
    "\n",
    "- change the parameter '*data_dir*' in the *args* dictionary to change the subject to one of the following \n",
    "  - /kaggle/input/kumars-eeg-imagined-speech/Imagined_speech_EEG_edf/Digit/ \n",
    "  - /kaggle/input/kumars-eeg-imagined-speech/Imagined_speech_EEG_edf/Char/\n",
    "  - /kaggle/input/kumars-eeg-imagined-speech/Imagined_speech_EEG_edf/Image/\n",
    "- remenber to change also the '*save_dir*' parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_args():\n",
    "    args = {\n",
    "        'class_num': 10,\n",
    "        'dropout': 0.1 ,\n",
    "        'nhead': 2 ,\n",
    "        'dim_feedforward': 256 ,\n",
    "        'num_layers': 5 ,\n",
    "        'embed_dim': 14,\n",
    "        'vocab_size': 32,\n",
    "        'kernel_num': 128,\n",
    "        'kernel_size': 3, \n",
    "        'batch_size': 256, # use low batch size\n",
    "        'epochs': 1000 ,\n",
    "        'early_stopping_patience': 300,\n",
    "        'lr': 0.9 ,\n",
    "        'log_interval': 1,\n",
    "        'device': 'cuda:1' if torch.cuda.is_available() else 'cpu',\n",
    "        'data_dir': '/home/jovyan/nfs/igallo/datasets/EEG/thoughtvizdataset/raw/', # Digit/, Char/, Image/\n",
    "        'save_dir': 'experiments/transformer/', # char_raw, digit_raw, image_raw\n",
    "        'save_best': True,\n",
    "        'verbose': True,\n",
    "        'test_interval': 100,\n",
    "        'save_interval': 500,\n",
    "        'sampling_rate': 128,\n",
    "    }\n",
    "    #args['device'] = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation 2\n",
    "- NO Conv2\n",
    "- NO Temporal transformer T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def single_run():\n",
    "    subjects = [\"Char\", \"Digit\", \"Image\"]\n",
    "    for subj in subjects:\n",
    "        print(\"Subject:\", subj)\n",
    "        args = get_default_args()\n",
    "        args['data_dir'] = os.path.join(args['data_dir'], subj)\n",
    "        args['save_dir'] = os.path.join(args['save_dir'], f\"{subj.lower()}_raw\")\n",
    "        create_save_dir(args)\n",
    "\n",
    "        model = NetTraST(args)\n",
    "        model = model.to(args['device'])\n",
    "\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters()) #, lr=args['lr'])\n",
    "\n",
    "        with open(os.path.join(args['save_dir'], \"config.yaml\"), \"w\") as f:\n",
    "            yaml.dump(\n",
    "                args, stream=f, default_flow_style=False, sort_keys=False\n",
    "            )\n",
    "\n",
    "        train_loader, test_loader = read_kumar_raw(args) \n",
    "        print(\"Training size:\", len(train_loader.dataset))\n",
    "        print(\"Test size:\", len(test_loader.dataset))\n",
    "\n",
    "        train_raw(args, model, train_loader, optimizer, criterion, test_loader, subj) \n",
    "        #torch.save(model, os.path.join(args['save_dir'], f\"{model.__class__.__name__}_model_last.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Char\n",
      "Dataset dir: /home/jovyan/nfs/igallo/datasets/EEG/thoughtvizdataset/raw/Char\n",
      "{'a': 0, 'c': 1, 'f': 2, 'h': 3, 'j': 4, 'm': 5, 'p': 6, 's': 7, 't': 8, 'y': 9}\n",
      "Lenght Time series: MIN=1536, MAX=1920\n",
      "Max value in Time series: 0.007820512820512819\n",
      "Num raw files: 230\n",
      "Num channels: 14\n",
      "Input data: mean = 4.228270597865398 , std = 0.119855313949292\n",
      "Kumar Dataset shape: (36110, 32, 14) , min: 0.24717948717948718 , max: 7.820512820512819\n",
      "Training shape: torch.Size([28888, 32, 14])\n",
      "Test shape: torch.Size([7222, 32, 14])\n",
      "Training size: 28888\n",
      "Test size: 7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subj.: Char, Training epoch: 1000: 100%|██████████| 1000/1000 [1:51:33<00:00,  6.69s/it, Best val. acc.: 88.1750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Digit\n",
      "Dataset dir: /home/jovyan/nfs/igallo/datasets/EEG/thoughtvizdataset/raw/Digit\n",
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}\n",
      "Lenght Time series: MIN=1408, MAX=2304\n",
      "Max value in Time series: 0.00795179487179487\n",
      "Num raw files: 230\n",
      "Num channels: 14\n",
      "Input data: mean = 4.227561717040576 , std = 0.1405851507130073\n",
      "Kumar Dataset shape: (36110, 32, 14) , min: 0.41128205128205125 , max: 7.9517948717948705\n",
      "Training shape: torch.Size([28888, 32, 14])\n",
      "Test shape: torch.Size([7222, 32, 14])\n",
      "Training size: 28888\n",
      "Test size: 7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subj.: Digit, Training epoch: 1000: 100%|██████████| 1000/1000 [2:01:41<00:00,  7.30s/it, Best val. acc.: 87.8289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Image\n",
      "Dataset dir: /home/jovyan/nfs/igallo/datasets/EEG/thoughtvizdataset/raw/Image\n",
      "{'apple': 0, 'car': 1, 'dog': 2, 'gold': 3, 'mobile': 4, 'rose': 5, 'scooter': 6, 'tiger': 7, 'wallet': 8, 'watch': 9}\n",
      "Lenght Time series: MIN=1536, MAX=2816\n",
      "Max value in Time series: 0.00806\n",
      "Num raw files: 230\n",
      "Num channels: 14\n",
      "Input data: mean = 4.22922741685585 , std = 0.13057505350656873\n",
      "Kumar Dataset shape: (36110, 32, 14) , min: 0.5153846153846153 , max: 8.059999999999999\n",
      "Training shape: torch.Size([28888, 32, 14])\n",
      "Test shape: torch.Size([7222, 32, 14])\n",
      "Training size: 28888\n",
      "Test size: 7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subj.: Image, Training epoch: 1000: 100%|██████████| 1000/1000 [1:17:40<00:00,  4.66s/it, Best val. acc.: 85.7380]\n"
     ]
    }
   ],
   "source": [
    "single_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformers (Python 3.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
